{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You shall use annotated images in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should first download the Labelstudio repo  \n",
    "Go to the tutorial and annotate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing : sub-images algorithm and train-test-val split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUT-IMG algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def calculate_splits(W, H, subim_size, tol_width, tol_height, tol_xy):\n",
    "    N = (W + subim_size -1) // subim_size\n",
    "    M = (H + subim_size -1) // subim_size\n",
    "\n",
    "    while True:\n",
    "        if N==0 or M==0:\n",
    "            raise ValueError(f\"The passed image width and height need to be strictly positive.\")\n",
    "        if N==1 or W >= N * subim_size:\n",
    "            overlap_width = 0       # no overlap if only one image or if enough space for all subimages\n",
    "        else:\n",
    "            overlap_width = abs((W - N * subim_size) / (N-1))\n",
    "        if M==1 or H >= M * subim_size:\n",
    "            overlap_height = 0      # same along height axis\n",
    "        else:\n",
    "            overlap_height = abs((H - M * subim_size) / (M-1))\n",
    "        overlap_area_width = subim_size * overlap_width\n",
    "        overlap_area_height = subim_size * overlap_height\n",
    "        overlap_shared_area = overlap_height*overlap_width if N > 0 and M > 0 else 0\n",
    "\n",
    "        if overlap_area_width <= tol_width * subim_size ** 2:\n",
    "            if overlap_area_height <= tol_height * subim_size ** 2:\n",
    "                if overlap_shared_area <= tol_xy * subim_size ** 2:  # go out of the loop if all thresholds are satisfied\n",
    "                    print(f\"Overlapping width area : {100*overlap_width/subim_size}%\")\n",
    "                    print(f\"Overlapping height area : {100*overlap_height/subim_size}%\")\n",
    "                    print(f\"Overlapping shared area : {100*overlap_shared_area/(subim_size**2)}%\")\n",
    "                    break\n",
    "                else: # update N or M based on which threshold violation is greater\n",
    "                    if tol_height * subim_size ** 2 - overlap_area_height < tol_width * subim_size ** 2 - overlap_area_width:\n",
    "                        M -= 1\n",
    "                    else:\n",
    "                        N -= 1\n",
    "            else:\n",
    "                M -= 1\n",
    "        else:\n",
    "            N -= 1\n",
    "\n",
    "    return N, M, overlap_width, overlap_height\n",
    "\n",
    "def slice_image_and_boxes(image, bounding_boxes, W, H, subim_size, N, M, overlap_width, overlap_height, tol_bbox):\n",
    "    subimages = []\n",
    "    subimage_boxes = []\n",
    "\n",
    "    step_x = subim_size - overlap_width\n",
    "    step_y = subim_size - overlap_height\n",
    "\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            # Calculate subimage boundaries\n",
    "            start_x = int(j * step_x)\n",
    "            start_y = int(i * step_y)\n",
    "            end_x = min(start_x + subim_size, W)\n",
    "            end_y = min(start_y + subim_size, H)\n",
    "\n",
    "            # Extract subimage\n",
    "            subimage = image[start_y:end_y, start_x:end_x]\n",
    "            subimages.append(subimage)\n",
    "\n",
    "            # Adjust bounding boxes for subimage\n",
    "            subimage_bboxes = []\n",
    "            for bbox in bounding_boxes:\n",
    "                nw_x, nw_y, se_x, se_y = bbox    \n",
    "                if se_x < start_x or nw_x > end_x or se_y < start_y or nw_y > end_y:    # skip if the bounding box is outside the subimage\n",
    "                    continue\n",
    "                else :\n",
    "                    # Calculate the clipped bounding box coordinates\n",
    "                    clipped_nw_x = max(nw_x, start_x) - start_x\n",
    "                    clipped_nw_y = max(nw_y, start_y) - start_y\n",
    "                    clipped_se_x = min(se_x, end_x) - start_x\n",
    "                    clipped_se_y = min(se_y, end_y) - start_y\n",
    "\n",
    "                    if (clipped_se_x - clipped_nw_x)*(clipped_se_y - clipped_nw_y) < tol_bbox: # do not keep clipped bbox if area is less than tol_bbox pixels\n",
    "                        continue\n",
    "                    else:\n",
    "                        x = (clipped_nw_x + clipped_se_x) / 2\n",
    "                        w = clipped_se_x - clipped_nw_x\n",
    "                        y = (clipped_nw_y + clipped_se_y) / 2\n",
    "                        h = clipped_se_y - clipped_nw_y\n",
    "                        subimage_bboxes.append([x/subim_size, y/subim_size, w/subim_size, h/subim_size])\n",
    "                        # subimage_bboxes.append([clipped_nw_x, clipped_nw_y, clipped_se_x, clipped_se_y])\n",
    "            \n",
    "            # do not keep subimages without oranges\n",
    "            if subimage_bboxes==[]:\n",
    "                subimages.pop()\n",
    "            else:\n",
    "                subimage_boxes.append(subimage_bboxes)\n",
    "\n",
    "    return subimages, subimage_boxes\n",
    "\n",
    "def load_bbox(file_path, H, W):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        annotations = [list(map(float, line.strip().split()[1:])) for line in lines]\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for annotation in annotations:\n",
    "        x, y, w, h = annotation\n",
    "        x = int(x * W)\n",
    "        y = int(y * H)\n",
    "        w = int(w * W)\n",
    "        h = int(h * H)\n",
    "        nw_x = x - w // 2           \n",
    "        se_x = x +  w // 2          # top left corner       \n",
    "        nw_y = y - h // 2           # bottom right corner\n",
    "        se_y = y +  h // 2\n",
    "        bounding_boxes.append([nw_x, nw_y, se_x, se_y])\n",
    "\n",
    "    return bounding_boxes\n",
    "\n",
    "def main(SAVE_PATH, image_path, boxes_path, subim_size, weather_type, tol_width, tol_height, tol_xy, tol_bbox):\n",
    "    image = cv2.imread(image_path)\n",
    "    H, W = image.shape[:2]\n",
    "    bounding_boxes = load_bbox(boxes_path, H, W)\n",
    "\n",
    "    N, M, overlap_width, overlap_height = calculate_splits(W, H, subim_size, tol_width, tol_height, tol_xy)\n",
    "    print(f\"Splits: {N} along width, {M} along height\")\n",
    "    print(f\"Overlap: {overlap_width} pixels along width, {overlap_height} pixels along height\")\n",
    "\n",
    "    subimages, subimage_boxes = slice_image_and_boxes(image, bounding_boxes, W, H, subim_size, N, M, overlap_width, overlap_height, tol_bbox)\n",
    "\n",
    "    os.makedirs(SAVE_PATH + \"images\", exist_ok=True)\n",
    "    os.makedirs(SAVE_PATH + \"labels\", exist_ok=True)\n",
    "\n",
    "    for idx, (subimage, boxes) in enumerate(zip(subimages, subimage_boxes)):\n",
    "        subimage_filename = f\"{weather_type}_{datetime.now().strftime('%Y-%m-%d')}_{str(idx).zfill(2)}.jpg\"\n",
    "        cv2.imwrite(SAVE_PATH+\"images/\"+subimage_filename, subimage)\n",
    "\n",
    "        boxes_filename = SAVE_PATH+\"labels/\"+f\"{weather_type}_{datetime.now().strftime('%Y-%m-%d')}_{str(idx).zfill(2)}.txt\"\n",
    "        with open(boxes_filename, 'w') as f:\n",
    "            for box in boxes:\n",
    "                f.write(f\"0 {box[0]} {box[1]} {box[2]} {box[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example : imagine you are working with images of different resolutions.  \n",
    "### You want to create sub-images, split into train-test-val and provide the COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"\" # FINAL_ANNOTATED_FOLDER_FROM_ROBOFLOW\n",
    "SAVE_PATH = \"output_folder\"  \n",
    "for id, filename in enumerate(os.listdir(PATH+\"images\")):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = PATH+\"images/\"+filename\n",
    "        labels_path = PATH+\"labels/\"+filename.replace(\".jpg\", \".txt\")\n",
    "        main(SAVE_PATH, img_path, labels_path, subim_size=640, weather_type=\"AS\"+str(id).zfill(3), tol_width=0.3, tol_height=0.3, tol_xy=0.2, tol_bbox=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_bbox import train_test_val_folders\n",
    "\n",
    "# will split the images from the AS folder into three subfolders: train, test and val\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "train_test_val_folders(\"output_folder/\", TRAIN_SPLIT, VAL_SPLIT) # TEST_SPLIT will be 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO format (still with AS example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_to_coco import all_yolo_to_coco\n",
    "\n",
    "PATH=\"output_folder/\"\n",
    "\n",
    "images_dir = PATH+\"train/images\"\n",
    "labels_dir = PATH+\"train/labels\"\n",
    "output_file = PATH+\"train/annotations.json\"\n",
    "all_yolo_to_coco(images_dir, labels_dir, output_file)\n",
    "\n",
    "images_dir = PATH+\"val/images\"\n",
    "labels_dir = PATH+\"val/labels\"\n",
    "output_file = PATH+\"val/annotations.json\"\n",
    "all_yolo_to_coco(images_dir, labels_dir, output_file)\n",
    "\n",
    "images_dir = PATH+\"test/images\"\n",
    "labels_dir = PATH+\"test/labels\"\n",
    "output_file = PATH+\"test/annotations.json\"\n",
    "all_yolo_to_coco(images_dir, labels_dir, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
